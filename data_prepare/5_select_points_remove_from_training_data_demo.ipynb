{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fa9d3b",
   "metadata": {},
   "source": [
    "This script is used for:\n",
    "- remove \"pred points\" from training data \n",
    "\n",
    "**How to launch this Jupyter notebook**:   \n",
    "```bash\n",
    "execcasper -A your_project -l gpu_type=v100 -l walltime=06:00:00 -l select=1:ncpus=18:mpiprocs=36:ngpus=1:mem=300GB\n",
    "bash aws_urban_env.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c1dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import statsmodels.api as sm\n",
    "\n",
    "start_year = \"2006\"\n",
    "end_year = \"2015\"\n",
    "urban_LE_nc_path = \"/glade/scratch/zhonghua/urban_params/urban_LE/\"\n",
    "parquet_save_path = \"/glade/scratch/zhonghua/urban_params/urban_LE_random_split/\"\n",
    "urban_surf_path = \"/glade/scratch/zhonghua/urban_params/urban_surface.parquet.gzip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac7c582b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 31/31 [00:07<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if three points are still in the dataframe\n",
      "[Empty DataFrame\n",
      "Columns: [time, lat, lon, TREFMXAV_U, FLNS, FSNS, PRECT, PRSN, QBOT, TREFHT, UBOT, VBOT, member]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [time, lat, lon, TREFMXAV_U, FLNS, FSNS, PRECT, PRSN, QBOT, TREFHT, UBOT, VBOT, member]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [time, lat, lon, TREFMXAV_U, FLNS, FSNS, PRECT, PRSN, QBOT, TREFHT, UBOT, VBOT, member]\n",
      "Index: []]\n",
      "number of removed samples: 11206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = {\n",
    "    \"label\":\"TREFMXAV_U\",\n",
    "    \"CAM\": ['FLNS','FSNS','PRECT','PRSN','QBOT','TREFHT','UBOT','VBOT'],\n",
    "    \"surf\":['CANYON_HWR','EM_IMPROAD','EM_PERROAD','EM_ROOF','EM_WALL', \n",
    "            'HT_ROOF','THICK_ROOF','THICK_WALL','T_BUILDING_MAX','T_BUILDING_MIN',\n",
    "            'WTLUNIT_ROOF','WTROAD_PERV','NLEV_IMPROAD','PCT_URBAN',\n",
    "            'ALB_IMPROAD','ALB_PERROAD','ALB_ROOF','ALB_WALL',\n",
    "            'TK_ROOF','TK_WALL','CV_ROOF','CV_WALL',\n",
    "            'TK_IMPROAD_0','CV_IMPROAD_0','TK_IMPROAD_1','CV_IMPROAD_1'],\n",
    "    \"loc\":[\"lat\",\"lon\"]\n",
    "}\n",
    "\n",
    "def get_merge_member(start_year, end_year, parquet_save_path):\n",
    "    df_tmp_ls = []\n",
    "    for member_id in tqdm(range(3, 34)):\n",
    "        member = (str(member_id).zfill(3))\n",
    "        df_tmp_ls.append(pd.read_parquet(parquet_save_path + \"train/\" + member + \"_\"\\\n",
    "                            + start_year + \"_\" + end_year + \".parquet.gzip\", engine=\"fastparquet\"))\n",
    "    return pd.concat(df_tmp_ls)\n",
    "\n",
    "# load data\n",
    "urban_LE = get_merge_member(start_year, end_year, parquet_save_path)\n",
    "urban_surf = pd.read_parquet(urban_surf_path, engine=\"fastparquet\").reset_index()\n",
    "\n",
    "\n",
    "# ========= remove points from training data =========\n",
    "\n",
    "## known gridcell (lat, lon) <-> test gridcell (lat, lon)\n",
    "known_gridcell = {\n",
    "    \"1\": {\"lat\":32.51309, \"lon\":253.75},\n",
    "    \"2\": {\"lat\":40.994766, \"lon\":277.5},\n",
    "    \"3\": {\"lat\":40.994766, \"lon\":247.5}\n",
    "}\n",
    "\n",
    "pred_gridcell = {\n",
    "    \"1\": {\"lat\":31.57068, \"lon\":253.75},\n",
    "    \"2\": {\"lat\":41.937172, \"lon\":277.5},\n",
    "    \"3\": {\"lat\":42.87958, \"lon\":247.5}\n",
    "}\n",
    "\n",
    "dd = []\n",
    "for p in pred_gridcell:\n",
    "    dd.append(urban_LE[(np.abs(urban_LE[\"lat\"]-pred_gridcell[p][\"lat\"])<0.0001) & \n",
    "                       (np.abs(urban_LE[\"lon\"]-pred_gridcell[p][\"lon\"])<0.0001)])\n",
    "    \n",
    "urban_LE_new = urban_LE.drop(pd.concat(dd).index).copy()\n",
    "\n",
    "# check if we removed points successfully\n",
    "dd = []\n",
    "for p in pred_gridcell:\n",
    "    dd.append(urban_LE_new[(np.abs(urban_LE_new[\"lat\"]-pred_gridcell[p][\"lat\"])<0.0001) & \n",
    "                           (np.abs(urban_LE_new[\"lon\"]-pred_gridcell[p][\"lon\"])<0.0001)])\n",
    "\n",
    "print(\"check if three points are still in the dataframe\")\n",
    "print(dd)\n",
    "\n",
    "print(\"number of removed samples:\", urban_LE.shape[0] - urban_LE_new.shape[0])\n",
    "\n",
    "# merge data\n",
    "df = pd.merge(urban_LE_new, urban_surf, on = [\"lat\",\"lon\"], how = \"inner\")\n",
    "# check if we merge the data successfully\n",
    "assert urban_LE_new.shape[0] == df.shape[0]\n",
    "\n",
    "del urban_LE, urban_LE_new, urban_surf\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
